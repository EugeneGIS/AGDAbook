---
title: "Towards Geo-Data Science"
author: "Dr. Marj Tonini^[IDYST, University of Lausanne, marj.tonini@unil.ch]"
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output:
  pdf_document: default
  html_document: default
  toc: yes
  word_document: default
subtitle: 'Interpretability & Explainability in Random Forest'
editor_options:
  chunk_output_type: inline
  markdown:
    wrap: sentence
urlcolor: blue
bibliography: RF.bib
---

```{r  global-options, echo = FALSE}
knitr::opts_chunk$set( fig.align = "center",
	message = FALSE,
	warning = FALSE)

library(distill) #R Markdown' Format for Scientific and Technical Writing
```

# 1) Interpretability and Explainability Machine Learinig

## 1.1) Some definitinions

The distinction between interpretability and explainability lies in their **focus and depth**.

-   *Interpretability* delves into comprehending the inner mechanisms of the algorithm.

-   *Explainability* aims to elucidate the decisions is makes.

**Model complexity:** when dealing with intricate models like Random Forest (with tens of variables and thousands of trees), up to deep neural networks, *interpretability* becomes challenging due to their complexity and the interplay among their components.
In such scenarios, *explainability* proves to be a more practical approach, as it focuses on clarifying decisions rather than delving into the complexities of the model.

**Communication**: in terms of audience and purpose, *interpretability* primarily concerns AI specialists and researchers, whereas *explainability* targets end users seeking to grasp model decisions.
Consequently, explainability necessitates a more straightforward and intuitive communication of information.

## 1.2) Aim of the present lab

In this exercise you will work with the outputs of Random Forest resulting from the landslides susceptibility map project (LSM_RF).

-   Firstly, we will explore the relative importance of the predictor variables, and then their relative probability of prediction success.

-   Finally we will apply a local version of Random Forest (named Geographical Random Forest) to analyse the spatial heterogeneity of the local variable importance.

## 1.3) Re-load lybraries and workspace

If you have quit the workspace where you have run the RF model for landslide susceptibility map you need to load it again in this new project.
"*Loading the workspace*" refers to the action of restoring the saved state of the R environment.
When you save your workspace in R, it typically includes all the objects (such as variables, functions, data frames, etc.) that are currently present in your R session.
Loading the workspace means to restore this saved state, bringing back all the previously saved objects into your current R session.

```{r import-WS, echo = FALSE}

# Load the workspace (all the data)
load("LSM_RF.RData")

# Load the required libraries
## See details from the LSM_RF project
library(terra)
library(foreign)
library(readr) 
library(dplyr) 
library(pROC) 
library(plotROC) 
library(ggplot2)  
library(classInt)
library(randomForest)
library(tidyr)
library(RColorBrewer)
(.packages())
```

# 2) Variable importance plot

Although machine learning algorithms are often considered as a black box, with RF is possible to plot a sample tree (selected randomly) to analyse its structure and investigate how decisions have been made.
In addition RF provides two metrics allowing to assess the importance of each variables in the model: the mean decrease in accuracy (MDA), and the mean decrease in Gini index.
Higher values indicate the most important variables.

```{r plot-tree, fig.show='hide'}

library("party")
x <- ctree(LS~., data=LS_train)
plot(x, type="simple")
```

```{r var-imp, results = FALSE}

# Display the plot with the relative importance of each variable
importance(RF_LS)
varImpPlot(RF_LS)
```

## 2.1) Partial dependence plot

In addition, the Partial Dependence Plot (PDP) allows to estimate, for each single variable, the relative probability of prediction success over different ranges of values.
It gives a graphical depiction of the marginal effect of each variable on the class probability over different ranges of continuous or discrete values.
Positive values are associated with the probability of occurrence of the phenomena (i.e., landslides presence), while negative vales indicate its absence.

```{r par-plot}

# Slope
partialPlot(RF_LS, LS_train, x.var = slope, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "Slope [Â°]", 
            main = "", ylab = "PDP")

# Elevation
partialPlot(RF_LS, LS_train ,x.var = DEM, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "Elevation [m]", 
            main = "",ylab = "PDP")

# Profile curvature
partialPlot(RF_LS, LS_train, x.var = profCurv, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "Profile curvature [1/m]", 
            main = "", ylab = "PDP", xlim = c(-0.1,0.1))

# Plan Curvature
partialPlot(RF_LS, LS_train, x.var = planCurv, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "Plan curvature [1/m]", 
            main = "", ylab = "PDP", xlim = c(-0.1,0.1))

# Distance to road
partialPlot(RF_LS, LS_train, x.var = distRoad, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "Distance to road [m]", 
            main = "", ylab = "PDP")

# Topographic wetness index
partialPlot(RF_LS, LS_train, x.var = TWI, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "TWI [-]", 
            main = "", ylab = "PDP")

# Geology
partialPlot(RF_LS, LS_train, x.var = geology, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "Geology", 
            main = "", ylab = "PDP")

# Land cover
partialPlot(RF_LS, LS_train, x.var = landCover, rug = TRUE, 
            which.class = RF_LS$classes[2],xlab= "Land Cover",
            main = "", ylab = "PDP")
```

# 2) Local Random Forest

Standard machine learning algorithms like Random Forest (RF) lack spatial calibration, hindering capturing the spatial non-stationarity in the relationship between a dependent and a set of independent variables.

To account for the spatial heterogeneity (i.e. non-stationarity) when modeling landslides spatial patterns as function of geographical features, in the present work we explore the **local feature importance** of geographical independent predisposing variables on the spatial distribution of landslides in canton Vaud (Switzerland).

We adopted **Geographically Random Forest** (GRF), a spatial analysis method using a local version of RF algorithm [@georganos_forest_2022] .
This is achieved by fitting a sub-model for each observation in space, taking into account the neighbouring observations.
GRF can model the non-stationarity coupled with a non-linear model (RF) which tends not to overfit due to its bootstrapping nature.
In addition it is suited for datasets with numerous predictors.

Essentially, GRF was designed to be a bridge between machine learning and geographical models, combining inferential and explanatory power.

## 2.1) Run GRF

We will use the last development of **Geographical Random Forest** (GRF) [4].
This function have been implemented for regression problem, so we need to transform our binary response variable (i.e., presence=1 / absence = 0) as a numeric value which can assume a range of values from zero to one.

```{r GRF-input, echo = FALSE}

# Load SpatialML: it implements a spatial extension of the random forest algorithm 
library (SpatialML)

str(LS_input)

# Add LS as numerical variable for RF regression 
LS_train$LSregr = as.numeric(as.character(LS_train$LS))
LS_test$LSregr = as.numeric(as.character(LS_test$LS))
str(LS_train)
str(LS_test)
```

```{r Run-GRF}

Coords<-LS_train[,9:10] # define coordinates

# Run GRF

set.seed(123) # initialize 

gwRF_LS<-grf(LSregr~distRoad+DEM+landCover+TWI+planCurv+profCurv+slope+geology,  LS_train, bw=40, mtry=3, kernel="adaptive",coords=Coords)

saveRDS(gwRF_LS, "gwRF_LS.rds")
```

### 2.1.1) Global variable importance plot

Based on the results of the GRF, we present a plot of the variable importance ranking for illustrative purposes.
Values came from "Global ML Model Summary" - "Importance.

```{r Global-Var-Imp}

# Create a data frame with variable names and importance values
variable_importance <- data.frame (
  Variable = c("distRoad", "DEM", "landCover", "TWI", "planCurv", "profCurv", "slope", "geology"),
  Importance = c(181.18490, 114.32444,  34.23643, 101.51863,  84.81667, 125.93651, 297.74411,  39.22721 ) # Importance - Global ML
)

# Assign different colors to the top three important variables
variable_importance$Color <- ifelse(variable_importance$Importance >= sort(variable_importance$Importance, decreasing = TRUE)[3], "orange", "skyblue")

# Create a bar plot for variable importance with different colors for the top three variables
ggplot(data = variable_importance, aes(x = Variable, y = Importance, fill = Color)) +
  geom_bar(stat = "identity") +
  scale_fill_identity() +
  labs(title = "Variable Importance Plot", x = "Variable", y = "Importance") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability

```

### 2.1.2) Local Variable importance

### - Slope

```{r Slope_Imp}

# Create a data frame with the values of the local variables importance and the coordinates for each location¨
gwRF_LS_var<-gwRF_LS$Local.Variable.Importance
gwRF_LS_var_XY<-cbind(gwRF_LS_var,LS_train$x,LS_train$y ) # add coordinates
colnames(gwRF_LS_var_XY)[9]<- "X" #rename column X-coordinate 
colnames(gwRF_LS_var_XY)[10]<- "Y" #rename column Y-coordinate 
str(gwRF_LS_var_XY) 

library(sf) #for spatial data operations
# Convert vector to sf (simple feature)
Vaud<-vect("Vaud_CH.shp")
Vaud_sf<-st_as_sf(Vaud) 

# Output predicted values are transformed to a vector
pred.vect <- as.vector(gwRF_LS_var_XY$slope)

library(classInt) #for classification

brk<-(classIntervals(pred.vect, n=5, style = "fisher"))
brkInt<-round(brk$brks, digits=2)
print(brkInt)

#natural breaks (fisher)

ggplot() +
    geom_point(data = gwRF_LS_var_XY, aes(x = X, y = Y, colour = slope), size = 1) +
    scale_color_gradientn(colors = c("white", "orange","red", "blue"),  
                       breaks = c(0.00, 0.40, 1.15, 2.11, 3.23, 4.91), 
                       labels=c(0.00, 0.40, 1.15, 2.11, 3.23, 4.91)) +
        labs( x = "X Coordinate", y = "Y Coordinate")+
    ggtitle("Local average feature importance")+
    geom_sf(data = Vaud_sf, fill = "transparent", color = "black", size=2) #overlap borders
```

### - Distance to roads

```{r distRoad-Imp}

# Output predicted values are transformed to a vector
pred.vect <- as.vector(gwRF_LS$Local.Variable.Importance$distRoad)
 
brk<-(classIntervals(pred.vect, n=5, style = "fisher"))
brkInt<-round(brk$brks, digits=2)
print(brkInt) # print breaks

#natural breaks (fisher)

ggplot() +
    geom_point(data = gwRF_LS_var_XY, aes(x = X, y = Y, colour = distRoad), size = 1) +
    scale_color_gradientn(colors = c("white", "orange","red", "blue"), 
                       breaks = c(0.00, 0.37, 1.02, 2.17, 3.58, 4.85), 
                       labels=c(0.00, 0.37, 1.02, 2.17, 3.58, 4.85)) +
    labs( x = "X Coordinate", y = "Y Coordinate")+
    ggtitle("Local average feature importance")+
    geom_sf(data = Vaud_sf, fill = "transparent", color = "black", size=2) #overlap borders
```

## 2.1.3) Local R squared

The Local R-squared value ranges from 0 to 1 and represents the strength of the correlations of the local model on the features.

```{r local-R2}

Rsq<-gwRF_LS$LGofFit$LM_Rsq100
Rsq_XY<-as.data.frame(cbind(Rsq,LS_train$x,LS_train$y)) # add coordinates
colnames(Rsq_XY)[2]<- "X"
colnames(Rsq_XY)[3]<- "Y"
str(Rsq_XY)

ggplot () +
  geom_point(data = Rsq_XY, aes(x = X, y = Y, colour = Rsq), size = 1)+ 
  scale_color_gradientn(colors = c("white", "yellow","red", "blue"))+
  labs(title = "Rsq", x = "X Coordinate", y = "Y Coordinate")+
  ggtitle("Local R2")+
  geom_sf(data = Vaud_sf, fill = "transparent", color = "black", size=2) #overlap borders
```

# 6) Conclusions and further analyses

In the present exercise GRF has been used as a purely exploratory tool to estimate the spatial variation of the relationship between landslides in canton Vaud (Switzerland) and the influencing factors.
It allowed to elaborate maps delineating the local average importance of the most highly correlated features and to visualise the local fitting performance (R2 local value) into a map.

To be sure that everything is perfectly clear for you, we propose you to **answer the following questions** and to discuss your answers with the other participants to the course or directly with the teacher.

1.  Among the following angorithm evaluate them in therms of their interpretability and explainability: Support Vector Machines , linear regression, Deep Learning Models, Decision Trees, K-Nearest Neighbors, Neural Networks, Random Forests, logistic regression.

2.  Which are the three most important variables of your model (based on the MDA)?

3.  What is the slope value (or range of values) that gives the highest probability of landslides occurrence?
    And for the geology, which are the most important classes?

4.  Evaluate the spatial variation of the relationship between landslides and slope / distance to roads in your study area by visually inspecting the local average importance of these features.

5.  You can replicate this code (some chiuncks of it) to evaluate the local average importance of the third most important variable, as well as to map the local mean squared error.

# References
